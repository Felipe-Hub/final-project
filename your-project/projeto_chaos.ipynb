{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import nltk\n",
    "import re \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.stem import RSLPStemmer\n",
    "from string import punctuation\n",
    "from sklearn import metrics\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to prepare dataset ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:3: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:3: DeprecationWarning: invalid escape sequence \\d\n",
      "<ipython-input-57-9e0326d060fe>:3: DeprecationWarning: invalid escape sequence \\d\n",
      "  words = re.findall('[^\\d\\W]+', str(s))#, ' '.join(s))\n"
     ]
    }
   ],
   "source": [
    "# cleaning, stemming, tagging, removing stopwords\n",
    "def clean_up(s):\n",
    "    words = re.findall('[^\\d\\W]+', str(s))#, ' '.join(s))\n",
    "    #words = words.split()\n",
    "    words = [w.lower() for w in words if not w.startswith('http://') and len(w)>2]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    stop_words = stopwords.words('portuguese')\n",
    "    stop_words.append('ii')\n",
    "    stop_words.append('iii')\n",
    "    stop_words.append('iv')\n",
    "    stop_words.append('º')\n",
    "    stop_words.append('ª')\n",
    "    stop_words.append('nº')\n",
    "    return [word for word in l if word not in stop_words]\n",
    "\n",
    "# here we try stem and pos_tag to check, the lemmatization does not work well in portuguese\n",
    "## the pos tag was trainned below as 'tagger' with a specific algorithm for portuguese language\n",
    "def tag_stem(l):\n",
    "    tagged = tagger.tag(l)\n",
    "    words, tags = zip(*tagged)\n",
    "    stem = [RSLPStemmer().stem(word) for word in words]\n",
    "    return list(zip(stem,tags))\n",
    "\n",
    "# applying all\n",
    "def set_up(x):\n",
    "    return x.apply(clean_up).apply(word_tokenize).apply(remove_stopwords).apply(tag_stem)\n",
    "\n",
    "# this funcion will clean the english tags to be portuguese friendly\n",
    "def convert_to_universal_tag(t, reverse=False):\n",
    "    tagdict = {\n",
    "        'n': \"NOUN\",\n",
    "        'num': \"NUM\",\n",
    "        'v-fin': \"VERB\",\n",
    "        'v-inf': \"VERB\",\n",
    "        'v-ger': \"VERB\",\n",
    "        'v-pcp': \"VERB\",\n",
    "        'pron-det': \"PRON\",\n",
    "        'pron-indp': \"PRON\",\n",
    "        'pron-pers': \"PRON\",\n",
    "        'art': \"DET\",\n",
    "        'adv': \"ADV\",\n",
    "        'conj-s': \"CONJ\",\n",
    "        'conj-c': \"CONJ\",\n",
    "        'conj-p': \"CONJ\",\n",
    "        'adj': \"ADJ\",\n",
    "        'ec': \"PRT\",\n",
    "        'pp': \"ADP\",\n",
    "        'prp': \"ADP\",\n",
    "        'prop': \"NOUN\",\n",
    "        'pro-ks-rel': \"PRON\",\n",
    "        'proadj': \"PRON\",\n",
    "        'prep': \"ADP\",\n",
    "        'nprop': \"NOUN\",\n",
    "        'vaux': \"VERB\",\n",
    "        'propess': \"PRON\",\n",
    "        'v': \"VERB\",\n",
    "        'vp': \"VERB\",\n",
    "        'in': \"X\",\n",
    "        'prp-': \"ADP\",\n",
    "        'adv-ks': \"ADV\",\n",
    "        'dad': \"NUM\",\n",
    "        'prosub': \"PRON\",\n",
    "        'tel': \"NUM\",\n",
    "        'ap': \"NUM\",\n",
    "        'est': \"NOUN\",\n",
    "        'cur': \"X\",\n",
    "        'pcp': \"VERB\",\n",
    "        'pro-ks': \"PRON\",\n",
    "        'hor': \"NUM\",\n",
    "        'pden': \"ADV\",\n",
    "        'dat': \"NUM\",\n",
    "        'kc': \"ADP\",\n",
    "        'ks': \"ADP\",\n",
    "        'adv-ks-rel': \"ADV\",\n",
    "        'npro': \"NOUN\",\n",
    "    }\n",
    "    if t in [\"N|AP\",\"N|DAD\",\"N|DAT\",\"N|HOR\",\"N|TEL\"]:\n",
    "        t = \"NUM\"\n",
    "    if reverse:\n",
    "        if \"|\" in t: t = t.split(\"|\")[0]\n",
    "    else:\n",
    "        if \"+\" in t: t = t.split(\"+\")[1]\n",
    "        if \"|\" in t: t = t.split(\"|\")[1]\n",
    "        if \"#\" in t: t = t.split(\"#\")[0]\n",
    "    t = t.lower()\n",
    "    return tagdict.get(t, \".\" if all(tt in punctuation for tt in t) else t)\n",
    "\n",
    "# bag of words\n",
    "def bow(x, n=5000):\n",
    "    allwords = [w for words in x for w in words if len(w) > 1]\n",
    "    bag = {k:allwords.count(k) for k in allwords}\n",
    "    sorted_bag = sorted(bag.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    sb = {k:v for k,v in sorted_bag[:n]}\n",
    "    return pd.DataFrame(sb, index=['values'])\n",
    "\n",
    "# check if words are in text\n",
    "def find_features(document):\n",
    "    word = set(document)\n",
    "    return {w:(w in word) for w in words.columns}\n",
    "\n",
    "# multiply two lists\n",
    "def mult(a,b, c=[]):\n",
    "    for i in range(len(a)):\n",
    "        c.append(a[i]*b[i])\n",
    "    return c\n",
    "\n",
    "# separating words from tags\n",
    "def words(l):\n",
    "    words, tags = zip(*l)\n",
    "    return [word for word in words]\n",
    "\n",
    "def tags(l):\n",
    "    words, tags = zip(*l)\n",
    "    return [tag.lower() for tag in tags]\n",
    "\n",
    "# adding weights to each\n",
    "def weight(l, d):\n",
    "    res = []\n",
    "    for i in l:\n",
    "        try:\n",
    "            res.append(d[i])\n",
    "        except:\n",
    "            res.append(0)\n",
    "    return res\n",
    "\n",
    "# assign weights for vectors\n",
    "def assign_weights(a, b, c=[]):\n",
    "    for i in range(len(a)):\n",
    "        return [(a[i] * np.array(b[i])).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bypass an issue with the 64bit python version, i had to add the following function\n",
    "def hash32(value):\n",
    "    return hash(value) & 0xffffffff\n",
    "\n",
    "# to train the model i will apply this function\n",
    "# the funciont will take the word Series and the Tag series to train the model doc by doc\n",
    "def doc2vec_trainer(ws, ts, fname, c=0):\n",
    "    model_doc = Doc2Vec([TaggedDocument(ws[0], ts[0])], size = 100, window = 1, min_count = 1,\n",
    "                        workers=3, hashfxn=hash32, alpha=0.001, min_alpha=0.00025)\n",
    "    model_doc.save(fname)\n",
    "    for i in range(1, len(ws)):\n",
    "        model_doc.train([TaggedDocument(ws[i], ts[i])], total_examples=model_doc.corpus_count,\n",
    "                         epochs=model_doc.iter)\n",
    "        model_doc.alpha -= 0.0002 # adjusting the learning rate\n",
    "        model_doc.min_alpha = model_doc.alpha\n",
    "        model_doc.save(fname)\n",
    "        c+=1\n",
    "        print('Learned {} from {}!'.format(c, len(ws)))\n",
    "    print('Success! Model updated.')\n",
    "    return model_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model for Portuguese POS tagging\n",
    "For lemmatization to work well in portuguese language and to avoid ambiguity, we need to train the model for recognizing and tagging by the Part-of-Speech method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package floresta to\n",
      "[nltk_data]     C:\\Users\\Evelien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\floresta.zip.\n",
      "[nltk_data] Downloading package mac_morpho to\n",
      "[nltk_data]     C:\\Users\\Evelien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\mac_morpho.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('floresta')\n",
    "nltk.download('mac_morpho')\n",
    "# nltk.corpus.mac_morpho.tagged_sents is incorrect, converting tagged_paras to tagged_sents\n",
    "dataset1 = list(nltk.corpus.floresta.tagged_sents())\n",
    "dataset2 = [[w[0] for w in sent] for sent in nltk.corpus.mac_morpho.tagged_paras()]\n",
    "\n",
    "traindata = [[(w, convert_to_universal_tag(t)) for (w, t) in sent] for sent in dataset1]\n",
    "traindata2 = traindata + [[(w, convert_to_universal_tag(t, reverse=True)) for (w, t) in sent]\n",
    "                          for sent in dataset2]\n",
    "\n",
    "shuffle(traindata)\n",
    "shuffle(traindata2)\n",
    "\n",
    "regex_patterns = [(r\"^[nN][ao]s?$\", \"ADP\"), (r\"^[dD][ao]s?$\", \"ADP\"), (r\"^[pP]el[ao]s?$\", \"ADP\"),\n",
    "                  (r\"^[nN]est[ae]s?$\", \"ADP\"), (r\"^[nN]um$\", \"ADP\"), (r\"^[nN]ess[ae]s?$\", \"ADP\"),\n",
    "                  (r\"^[nN]aquel[ae]s?$\", \"ADP\"), (r\"^\\xe0$\", \"ADP\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model and getting tagger ready\n",
    "tagger = nltk.BigramTagger(\n",
    "            traindata, backoff=nltk.RegexpTagger(\n",
    "                regex_patterns, backoff=nltk.UnigramTagger(\n",
    "                    traindata2, backoff=nltk.AffixTagger(\n",
    "                        traindata2, backoff=nltk.DefaultTagger('NOUN')))))\n",
    "\n",
    "templates = nltk.brill.fntbl37()\n",
    "tagger = nltk.BrillTaggerTrainer(tagger, templates)\n",
    "tagger = tagger.train(traindata, max_rules=100)\n",
    "\n",
    "# saving model\n",
    "f = open('tagger.pickle', 'wb')\n",
    "pickle.dump(tagger, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.accuracy(tagger, traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data and getting text ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I.      De acordo com o despacho proferido nos...</td>\n",
       "      <td>2653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I.     Defere-se a presente reclamação para a ...</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I.  O estabelecimento hospital que contribuiu ...</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I - A Formação admitiu a revista excepcional, ...</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I Resulta do artigo 2109º, nº1 do CCivil que o...</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9845</td>\n",
       "      <td>I - A matéria de facto só pode ser alterada pe...</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9846</td>\n",
       "      <td>I - Em sede de saneador-sentença, o juiz deve,...</td>\n",
       "      <td>1693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9847</td>\n",
       "      <td>I. Para decidir se é ou não de atribuir relev...</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9848</td>\n",
       "      <td>I. O STJ pode censurar o mau uso que o Tribuna...</td>\n",
       "      <td>2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9849</td>\n",
       "      <td>I.       Constitui associação em participação ...</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9848 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   main   len\n",
       "0     I.      De acordo com o despacho proferido nos...  2653\n",
       "1     I.     Defere-se a presente reclamação para a ...   792\n",
       "2     I.  O estabelecimento hospital que contribuiu ...  1240\n",
       "3     I - A Formação admitiu a revista excepcional, ...  1807\n",
       "4     I Resulta do artigo 2109º, nº1 do CCivil que o...  1869\n",
       "...                                                 ...   ...\n",
       "9845  I - A matéria de facto só pode ser alterada pe...  1229\n",
       "9846  I - Em sede de saneador-sentença, o juiz deve,...  1693\n",
       "9847   I. Para decidir se é ou não de atribuir relev...  1789\n",
       "9848  I. O STJ pode censurar o mau uso que o Tribuna...  2826\n",
       "9849  I.       Constitui associação em participação ...   775\n",
       "\n",
       "[9848 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset and getting only unique values\n",
    "df = pd.read_csv('decisions.csv', index_col='Unnamed: 0')\n",
    "uniq = pd.DataFrame()\n",
    "uniq['main'] = df['Main Judgement'].unique()\n",
    "uniq['main'] = uniq['main'].dropna()\n",
    "uniq['len'] = uniq['main'].apply(str).apply(len)\n",
    "uniq = uniq[uniq['len'] > 50]\n",
    "uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Evelien/nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f1469a2a4114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# getting tokenized and applying predetermined functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtokens_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'main'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtokens_save\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-9e0326d060fe>\u001b[0m in \u001b[0;36mset_up\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# applying all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mset_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_up\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_stem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# this funcion will clean the english tags to be portuguese friendly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4040\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4042\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \"\"\"\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m     return [\n\u001b[0;32m    146\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \"\"\"\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    994\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Evelien/nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Evelien\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# loading pos_tags model for portuguese language\n",
    "f = open('tagger.pickle', 'rb')\n",
    "tagger = pickle.load(f)\n",
    "f.close()\n",
    "# getting tokenized and applying predetermined functions\n",
    "tokens_save = set_up(uniq['main'])\n",
    "tokens_save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens.json\", \"w\") as f:\n",
    "    json.dump(tokens_save.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokens.json') as json_data:\n",
    "    data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Dataframe\n",
    "Vectorizing all the words and tags, assigning weights to each and composing a dataframe with these features for further analysis and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[acord, NOUN], [despach, NOUN], [profer, VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[def, VERB], [pres, ADJ], [reclam, NOUN], [co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[estabelec, NOUN], [hospit, NOUN], [contribu,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[[form, NOUN], [admit, VERB], [revist, NOUN], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[[result, VERB], [artig, NOUN], [ccivil, NOUN]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                main\n",
       "0  [[acord, NOUN], [despach, NOUN], [profer, VERB...\n",
       "1  [[def, VERB], [pres, ADJ], [reclam, NOUN], [co...\n",
       "2  [[estabelec, NOUN], [hospit, NOUN], [contribu,...\n",
       "3  [[form, NOUN], [admit, VERB], [revist, NOUN], ...\n",
       "4  [[result, VERB], [artig, NOUN], [ccivil, NOUN]..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = pd.DataFrame()\n",
    "tokens['main'] = data.values()\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "features['main'] = tokens['main']\n",
    "features['words'] = tokens['main'].apply(words)\n",
    "features['tags'] = tokens['main'].apply(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing\n",
    "n=50\n",
    "model_w = Word2Vec(features['words'], min_count=1, size=n, workers=3, window=5, sg=1)\n",
    "model_t = Word2Vec(features['tags'], min_count=1, size=n, workers=3, window=5, sg=1)\n",
    "#model_w.most_similar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing the text with Tf idf\n",
    "vectorizer_w = TfidfVectorizer()\n",
    "vectorizer_w.fit_transform(features['words'].apply(' '.join))\n",
    "vec_dic_w = dict(zip(vectorizer_w.get_feature_names(), vectorizer_w.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_t = TfidfVectorizer()\n",
    "vectorizer_t.fit_transform(features['tags'].apply(' '.join))\n",
    "vec_dic_t = dict(zip(vectorizer_t.get_feature_names(), vectorizer_t.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['td_word'] = features['words'].apply(lambda x: [vec_dic_w[w] for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['td_tags'] = features['tags'].apply(lambda x: [\n",
    "                      vec_dic_t[t] if t in vec_dic_t else 1 for t in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['td_wxt'] = features.apply(lambda x: mult(x['td_word'], x['td_tags']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['weighted_tdidf'] = features.apply(lambda x: )\n",
    "#mult(features['td_word'][0], features['td_tags'][0])\n",
    "#mult([1,2,3], [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 223)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def td_idf(l1, l2, d):\n",
    "    for k in d:\n",
    "        if k in l1:\n",
    "            x = l2\n",
    "        else:\n",
    "            0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['weight_tdidf'] = features['words'].apply(\n",
    "                    lambda x: [v if k in x else 0 for k,v in vec_dic_w.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding tf idf as feature\n",
    "features['tdidf'] = features['words'].apply(\n",
    "                    lambda x: [v if k in x else 0 for k,v in vec_dic_w.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['tdidf_t'] = features['tags'].apply(\n",
    "                      lambda x: [vec_dic_t[] v if k in x else 0 for k,v in vec_dic_w.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460.0786111719869"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['td_tag_word'] = features['words']*features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding tf idf as weights\n",
    "features['weight_w'] = features['words'].apply(lambda x: weight(x, vec_dic_w))\n",
    "features['weight_t'] = features['tags'].apply(lambda x: weight(x, vec_dic_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# adding vectors\n",
    "features['vectors_w'] = features['words'].apply(lambda x: [model_w[w] for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-11b12af3118b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m features['vectors_w'] = features['words'].apply(\n\u001b[1;32m----> 2\u001b[1;33m                         lambda x: [model_w[w] if w in x else np.zeros(n) for w in vec_dic_w])\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# it might not be worth to vectorize the tags, maybe making them dummies is a better approuch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# features['vectors_t'] = features['tags'].apply(lambda x: [model_t[w] for w in x])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4043\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4045\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4047\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-11b12af3118b>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m features['vectors_w'] = features['words'].apply(\n\u001b[1;32m----> 2\u001b[1;33m                         lambda x: [model_w[w] if w in x else np.zeros(n) for w in vec_dic_w])\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# it might not be worth to vectorize the tags, maybe making them dummies is a better approuch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# features['vectors_t'] = features['tags'].apply(lambda x: [model_t[w] for w in x])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-11b12af3118b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m features['vectors_w'] = features['words'].apply(\n\u001b[1;32m----> 2\u001b[1;33m                         lambda x: [model_w[w] if w in x else np.zeros(n) for w in vec_dic_w])\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# it might not be worth to vectorize the tags, maybe making them dummies is a better approuch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# features['vectors_t'] = features['tags'].apply(lambda x: [model_t[w] for w in x])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features['vectors_w'] = features['words'].apply(\n",
    "                        lambda x: [model_w[w] if w in x else np.zeros(n) for w in vec_dic_w])\n",
    "# it might not be worth to vectorize the tags, maybe making them dummies is a better approuch \n",
    "# features['vectors_t'] = features['tags'].apply(lambda x: [model_t[w] for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dummies\n",
    "tags = pd.Series([i for ii in features['tags'] for i in ii]).unique()\n",
    "\n",
    "for c in tags:\n",
    "    features[c] = features['tags'].apply(lambda x: [1 if t == c else 0 for t in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [204.5034159558449, -87.62844604194666, 208.42...\n",
       "1       [36.22991062970964, -17.777194011136668, 33.04...\n",
       "2       [112.7604887675096, -56.5621460817556, 91.7640...\n",
       "3       [77.2860801302986, -70.24553094875054, 109.518...\n",
       "4       [199.03621543645858, -61.46741759711002, 162.6...\n",
       "                              ...                        \n",
       "9843    [118.80132786379683, -62.090736347056136, 97.0...\n",
       "9844    [80.3518284392613, -67.16384545796089, 132.145...\n",
       "9845    [198.38254171590046, -116.2080826108005, 84.54...\n",
       "9846    [181.25976429522734, -91.30012141223202, 179.1...\n",
       "9847    [62.41769913203094, -27.29416976415753, 31.355...\n",
       "Name: word_v, Length: 9848, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying weights\n",
    "## confirm if we should use dot or normal multiplication\n",
    "#assign_weights = lambda x: [(x['weight_w'][i] * np.array(x['vectors_w']))\n",
    "#                             for i in range(len(x['weight_w']))]\n",
    "\n",
    "features['word_v'] = features[['weight_w', 'vectors_w']].apply(lambda x: np.dot(np.array(x['weight_w']), np.array(x['vectors_w'])), axis=1)\n",
    "features['word_v']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polarity Checking for Positive/Negative rullings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(uniq['main'].apply(lambda x: 1 if len(re.findall('improced.+', x)) > 0 else 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to try separeting the positive and negative rullings i will do an average of words,\n",
    "# usually related to negative outcome:\n",
    "lengths = features['words'].apply(len)\n",
    "polar = np.diag(uniq['main'].apply(lambda x: (len(re.findall('nem', x))+len(re.findall('não', x))+\\\n",
    "                                   len(re.findall('inexiste', x))+\\\n",
    "                                   len(re.findall('negado', x))+\\\n",
    "                                   len(re.findall('deveria', x))+len(re.findall('falta', x))+\\\n",
    "                                   len(re.findall('demonstre', x))+\\\n",
    "                                   len(re.findall('improced.+', x))*1.5+\\\n",
    "                                   len(re.findall('insucesso', x)))/lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for positive, 0 for negative \n",
    "features['polarity'] = [1 if p <= 0.03 else 0 for p in polar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(features['vectors_w'][0][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.to_csv('features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2299    caus discut respons advog insucess obt noutr a...\n",
       "6297    requisit juíz reprov aquis alud norm estabelec...\n",
       "578     admiss recurs revist term art cir recorr além ...\n",
       "7279    administr part comum edifíci pertenc compropri...\n",
       "3630    indic númer alvar dat emiss câm municip escrit...\n",
       "                              ...                        \n",
       "9261    princípi geral proib anatoc estabelec art civ ...\n",
       "2419    decis judic decl nulidad act administr plur ca...\n",
       "768     cláusul penal compensatór cons estipul antecip...\n",
       "3366    compet internac tribun portugues dev ser afer ...\n",
       "5815    sobr decis cont sentenç acórd sobr fundament f...\n",
       "Name: words, Length: 7878, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(features['words'].apply(' '.join))\n",
    "y = np.array(features['polarity'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:   16.5s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 516, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 352, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 317, in _fit\n    **fit_params_steps[name])\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\memory.py\", line 355, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 716, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1652, in fit_transform\n    X = super().fit_transform(raw_documents)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1058, in fit_transform\n    self.fixed_vocabulary_)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 970, in _count_vocab\n    for feature in analyze(doc):\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 352, in <lambda>\n    tokenize(preprocess(self.decode(doc))), stop_words)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 256, in <lambda>\n    return lambda x: strip_accents(x.lower())\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\scipy\\sparse\\base.py\", line 688, in __getattr__\n    raise AttributeError(attr + \" not found\")\nAttributeError: lower not found\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-006f3d11ab6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m \u001b[0mgrid_search_tune\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgrid_search_tune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mbest_svc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search_tune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "pipeline = Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', OneVsRestClassifier(\n",
    "                            LinearSVC(), n_jobs=1))])\n",
    "\n",
    "parameters = {\"clf__estimator__C\": [0.01, 0.1, 1],\n",
    "        \"clf__estimator__class_weight\": ['balanced', None]}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=3, verbose=10)\n",
    "grid_search_tune.fit(X_train,y_train)\n",
    "best_svc = grid_search_tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       938\n",
      "           1       0.65      0.61      0.63      1032\n",
      "\n",
      "    accuracy                           0.63      1970\n",
      "   macro avg       0.63      0.63      0.63      1970\n",
      "weighted avg       0.63      0.63      0.63      1970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_svc = best_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "cross_val_score(best_svc, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC\n",
    "pipeline = Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', OneVsRestClassifier(\n",
    "                            RandomForestClassifier(), n_jobs=1))])\n",
    "## best param = 401\n",
    "parameters = {\"clf__estimator__n_estimators\": list(range(1,1000,100))}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=3, verbose=10)\n",
    "grid_search_tune.fit(X_train,y_train)\n",
    "best_svc = grid_search_tune.best_estimator_\n",
    "\n",
    "y_pred_svc = best_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "cross_val_score(best_svc, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "parameters = {'n_neighbors': np.arange(1,10), 'weights': ['uniform', 'distance']} \n",
    "knn = KNeighborsClassifier()\n",
    "grid_search_tune = GridSearchCV(knn, parameters, cv=5)\n",
    "grid_search_tune.fit(X_train,y_train)\n",
    "best_knn = grid_search_tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.39      0.45       938\n",
      "           1       0.54      0.66      0.60      1032\n",
      "\n",
      "    accuracy                           0.53      1970\n",
      "   macro avg       0.53      0.53      0.52      1970\n",
      "weighted avg       0.53      0.53      0.52      1970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_knn = best_knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the models with Word2Vec\n",
    "Here we will use BernoulliNB for incremental learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# resizing data\n",
    "X = np.array(X.tolist())\n",
    "y = np.array(y.tolist())\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# resizing data\n",
    "X = np.array(X.tolist())\n",
    "y = np.array(y.tolist())\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging word vectors per document, considering td idf as weight\n",
    "def averager(l):\n",
    "    return\n",
    "averager([[1,2],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = BernoulliNB()\n",
    "model_w2v = features.apply(lambda x: w2v_incremental(\n",
    "            x['vectors_w'][:20], x['polarity'][:20], model_b, 'w2v_inc.model'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_incremental(X, y, model, fname):\n",
    "    model.load(fname)\n",
    "    \n",
    "    model_w2v = grid.fit(X_train, y_train)\n",
    "    pickle.dump(model, open(fname, 'wb'))\n",
    "    return model_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = best_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering with Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features['tdidf'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dfd94fa808>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer = KElbowVisualizer(KMeans(), k=(1,20))\n",
    "visualizer.fit(X)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelk_end = KMeans(n_clusters=3)\n",
    "modelk_end.fit(np.array(X))\n",
    "features['kpos_neg'] = modelk_end.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelk_topics = KMeans(n_clusters=visualizer.elbow_value_)\n",
    "modelk_topics.fit(np.array(X))\n",
    "features['ktopics'] = modelk_topics.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "bow = bow(features['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Documents:\n",
    "##### word2vec & AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model\n",
    "doc2vec_trainer(features['words'], features['words'], \"d2v.model\")\n",
    "model_doc = Doc2Vec.load(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc.docvecs[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize documents\n",
    "X = np.array([model_doc.infer_vector(x) for x in features['words']])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train clustering model\n",
    "clustering = AffinityPropagation().fit(X)\n",
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers_indices = clustering.cluster_centers_indices_ \n",
    "labels = clustering.labels_ \n",
    "  \n",
    "n_clusters_ = len(cluster_centers_indices) \n",
    "\n",
    "labels, n_clusters_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting bag of word ready for bayes\n",
    "#documents = list(zip(corpus, np.where(ds['target'] == 4, True, False)))\n",
    "#featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "#train_set, test_set = featuresets[200:], featuresets[:200]\n",
    "#classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "#nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remember to take off 'não' to check\n",
    "print(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [acord, despach, profer, aut, pres, cas, decis...\n",
       "1       [def, pres, reclam, confer, admit, recurs, cir...\n",
       "2       [estabelec, hospit, contribu, trat, assist, ví...\n",
       "3       [form, admit, revist, excepc, fundament, art, ...\n",
       "4       [result, artig, ccivil, val, bem, do, mesm, da...\n",
       "                              ...                        \n",
       "9843    [matér, fact, pod, ser, alter, stj, verif, alg...\n",
       "9844    [sed, sane, sentenç, juiz, dev, term, art, cpc...\n",
       "9845    [decid, atribu, relev, caus, exclus, culp, ale...\n",
       "9846    [stj, pod, censur, mau, uso, tribun, relaç, ev...\n",
       "9847    [constitu, associ, particip, situ, alguém, exe...\n",
       "Name: words, Length: 9848, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_dic_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.DataFrame(vec_dic_w, index=features['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vec_for_learning(doc2vec_model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "model = train_doc2vec_model(train_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([model_doc.infer_vector(x) for x in features['words']])\n",
    "y = np.array(features['polarity'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', OneVsRestClassifier(\n",
    "                            LinearSVC(), n_jobs=1))])\n",
    "\n",
    "parameters = {\"clf__estimator__C\": [0.01, 0.1, 1],\n",
    "        \"clf__estimator__class_weight\": ['balanced', None]}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=3, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    3.5s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 516, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 352, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 317, in _fit\n    **fit_params_steps[name])\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\joblib\\memory.py\", line 355, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 716, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1652, in fit_transform\n    X = super().fit_transform(raw_documents)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1058, in fit_transform\n    self.fixed_vocabulary_)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 970, in _count_vocab\n    for feature in analyze(doc):\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 352, in <lambda>\n    tokenize(preprocess(self.decode(doc))), stop_words)\n  File \"C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 256, in <lambda>\n    return lambda x: strip_accents(x.lower())\nAttributeError: 'numpy.ndarray' object has no attribute 'lower'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-df81895a93c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mgrid_search_tune\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid_search_tune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mbest_svc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search_tune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "grid_search_tune.fit(X_train,y_train)\n",
    "best_svc = grid_search_tune.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "lst_words = [i for ii in df['words'].str.split() for i in ii if len(i) > 1]\n",
    "corpora = ' '.join(df['words'])\n",
    "bow = {k: corpora.count(k) for k in lst_words}\n",
    "bow_corpus = [bow.doc2bow(word) for word in df['words'].str.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "parameters = {\"lda__estimator__n_components\": list(range(5,15)),\n",
    "              \"lda__estimator__learning_decay\": [0.5, 0.7, 0.9]}\n",
    "\n",
    "grid_search_tune = GridSearchCV(LdaMulticore(), parameters, cv=3, n_jobs=3, verbose=10)\n",
    "grid_search_tune.fit(bow_corpus)\n",
    "best_log = grid_search_tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(features['words'].apply(' '.join))\n",
    "\n",
    "#y = features['polarity']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "lda = LDA().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__________': 1,\n",
       " '________________': 1,\n",
       " '_________________________': 1,\n",
       " '______________________________': 1,\n",
       " 'aafdl': 3,\n",
       " 'aarr': 1,\n",
       " 'ab': 1,\n",
       " 'abaix': 24,\n",
       " 'abal': 46,\n",
       " 'abaliz': 2,\n",
       " 'abalro': 6,\n",
       " 'abandon': 122,\n",
       " 'abandonám': 1,\n",
       " 'abarc': 106,\n",
       " 'abarqu': 3,\n",
       " 'abarrac': 1,\n",
       " 'abastec': 19,\n",
       " 'abat': 28,\n",
       " 'abaç': 3,\n",
       " 'abdic': 26,\n",
       " 'abdom': 4,\n",
       " 'abdómen': 3,\n",
       " 'abe': 1,\n",
       " 'abeber': 1,\n",
       " 'abel': 3,\n",
       " 'aberr': 4,\n",
       " 'aberrati': 2,\n",
       " 'abert': 312,\n",
       " 'abl': 4,\n",
       " 'abla': 7,\n",
       " 'abol': 15,\n",
       " 'aboli': 2,\n",
       " 'abomin': 2,\n",
       " 'abon': 11,\n",
       " 'abonatóri': 1,\n",
       " 'abor': 2,\n",
       " 'abord': 60,\n",
       " 'aborrec': 5,\n",
       " 'abort': 9,\n",
       " 'abr': 74,\n",
       " 'abrag': 1,\n",
       " 'abrand': 7,\n",
       " 'abrang': 742,\n",
       " 'abranj': 7,\n",
       " 'abraç': 1,\n",
       " 'abrevi': 9,\n",
       " 'abreviat': 2,\n",
       " 'abrig': 474,\n",
       " 'abril': 100,\n",
       " 'abrir': 1,\n",
       " 'abrupt': 11,\n",
       " 'absolu': 1,\n",
       " 'absolut': 583,\n",
       " 'absolutór': 18,\n",
       " 'absolutóri': 3,\n",
       " 'absolv': 254,\n",
       " 'absort': 1,\n",
       " 'absorv': 13,\n",
       " 'absorç': 4,\n",
       " 'abst': 37,\n",
       " 'absten': 1,\n",
       " 'abstenh': 2,\n",
       " 'abstenç': 39,\n",
       " 'abstev': 5,\n",
       " 'abstiv': 2,\n",
       " 'abstr': 13,\n",
       " 'abstra': 28,\n",
       " 'abstract': 218,\n",
       " 'abstracç': 36,\n",
       " 'abstrat': 18,\n",
       " 'abstém': 6,\n",
       " 'absurd': 11,\n",
       " 'abund': 3,\n",
       " 'abundant': 1,\n",
       " 'abundat': 2,\n",
       " 'abus': 916,\n",
       " 'abusiv': 8,\n",
       " 'abíli': 1,\n",
       " 'ac': 6,\n",
       " 'acab': 103,\n",
       " 'academic': 1,\n",
       " 'académ': 7,\n",
       " 'acalent': 1,\n",
       " 'acam': 10,\n",
       " 'acaric': 1,\n",
       " 'acarret': 112,\n",
       " 'acas': 24,\n",
       " 'acat': 71,\n",
       " 'acautel': 75,\n",
       " 'acc': 6,\n",
       " 'acccion': 1,\n",
       " 'accidit': 8,\n",
       " 'accion': 191,\n",
       " 'accip': 1,\n",
       " 'accipi': 11,\n",
       " 'accipiend': 4,\n",
       " 'accordéon': 1,\n",
       " 'ace': 9,\n",
       " 'aced': 70,\n",
       " 'aceir': 1,\n",
       " 'aceit': 985,\n",
       " 'aceler': 6,\n",
       " 'acen': 4,\n",
       " 'acend': 2,\n",
       " 'acent': 2,\n",
       " 'acentu': 81,\n",
       " 'acentuad': 9,\n",
       " 'acepç': 40,\n",
       " 'acer': 1,\n",
       " 'acerc': 193,\n",
       " 'acert': 62,\n",
       " 'acertad': 2,\n",
       " 'acerv': 62,\n",
       " 'aces': 9,\n",
       " 'acess': 510,\n",
       " 'acessibil': 5,\n",
       " 'acessor': 1,\n",
       " 'acessoriedad': 20,\n",
       " 'acessorium': 2,\n",
       " 'acessór': 123,\n",
       " 'acessóri': 141,\n",
       " 'acetábul': 5,\n",
       " 'aceç': 5,\n",
       " 'ach': 99,\n",
       " 'acid': 1762,\n",
       " 'acident': 74,\n",
       " 'acim': 88,\n",
       " 'acion': 24,\n",
       " 'aclar': 24,\n",
       " 'aclarand': 3,\n",
       " 'acobert': 1,\n",
       " 'acoim': 3,\n",
       " 'acoit': 1,\n",
       " 'acolh': 188,\n",
       " 'acomet': 6,\n",
       " 'acomod': 8,\n",
       " 'acompanh': 220,\n",
       " 'acondic': 1,\n",
       " 'acondicion': 4,\n",
       " 'aconselh': 48,\n",
       " 'acontec': 418,\n",
       " 'aconteç': 6,\n",
       " 'acopl': 9,\n",
       " 'acord': 2014,\n",
       " 'acorr': 6,\n",
       " 'acost': 2,\n",
       " 'acredit': 15,\n",
       " 'acresc': 277,\n",
       " 'acrescent': 80,\n",
       " 'acrescid': 3,\n",
       " 'acritic': 3,\n",
       " 'acromi': 1,\n",
       " 'acromioplast': 1,\n",
       " 'acrá': 1,\n",
       " 'acrésc': 45,\n",
       " 'acrí': 4,\n",
       " 'acrómi': 1,\n",
       " 'act': 2692,\n",
       " 'actiom': 2,\n",
       " 'action': 4,\n",
       " 'activ': 1655,\n",
       " 'actu': 1057,\n",
       " 'actual': 164,\n",
       " 'actualistic': 2,\n",
       " 'actualiz': 41,\n",
       " 'actualizad': 3,\n",
       " 'actuar': 4,\n",
       " 'actum': 5,\n",
       " 'actur': 1,\n",
       " 'actv': 1,\n",
       " 'acuidad': 9,\n",
       " 'acuj': 3,\n",
       " 'acumul': 42,\n",
       " 'acus': 53,\n",
       " 'acutel': 1,\n",
       " 'acutil': 3,\n",
       " 'acç': 4016,\n",
       " 'acórd': 2034,\n",
       " 'acús': 5,\n",
       " 'adapt': 97,\n",
       " 'adaptad': 4,\n",
       " 'ade': 1,\n",
       " 'adeg': 2,\n",
       " 'adem': 59,\n",
       " 'adenocarcinom': 3,\n",
       " 'adentr': 2,\n",
       " 'adequ': 1048,\n",
       " 'adequad': 43,\n",
       " 'adeqú': 2,\n",
       " 'ader': 349,\n",
       " 'aderg': 1,\n",
       " 'ades': 213,\n",
       " 'adi': 11,\n",
       " 'adiant': 59,\n",
       " 'adiantad': 1,\n",
       " 'adic': 75,\n",
       " 'adicion': 11,\n",
       " 'adimpier': 4,\n",
       " 'adimpl': 2,\n",
       " 'adimple': 2,\n",
       " 'adimplet': 32,\n",
       " 'adir': 5,\n",
       " 'adit': 108,\n",
       " 'adivinh': 3,\n",
       " 'adiç': 5,\n",
       " 'adjac': 23,\n",
       " 'adje': 4,\n",
       " 'adjec': 115,\n",
       " 'adjectiv': 4,\n",
       " 'adjudic': 145,\n",
       " 'adjudicat': 6,\n",
       " 'adjudicatár': 3,\n",
       " 'adjudiqu': 2,\n",
       " 'adjunt': 27,\n",
       " 'adjunç': 1,\n",
       " 'adjuv': 14,\n",
       " 'adm': 4,\n",
       " 'adminicul': 3,\n",
       " 'adminiculum': 2,\n",
       " 'administr': 1237,\n",
       " 'administrativ': 9,\n",
       " 'admiss': 732,\n",
       " 'admissibil': 408,\n",
       " 'admissí': 1,\n",
       " 'admit': 743,\n",
       " 'admittuntur': 1,\n",
       " 'admnistr': 1,\n",
       " 'admoest': 1,\n",
       " 'admon': 4,\n",
       " 'admonit': 12,\n",
       " 'admonitór': 158,\n",
       " 'admonitóri': 19,\n",
       " 'admíssi': 1,\n",
       " 'adn': 13,\n",
       " 'adolesc': 4,\n",
       " 'adop': 2,\n",
       " 'adopt': 299,\n",
       " 'adopç': 95,\n",
       " 'adormec': 2,\n",
       " 'adorn': 2,\n",
       " 'adot': 48,\n",
       " 'adoç': 17,\n",
       " 'adqu': 21,\n",
       " 'adquir': 1372,\n",
       " 'adquis': 1,\n",
       " 'adr': 2,\n",
       " 'adred': 8,\n",
       " 'adreg': 4,\n",
       " 'adrenalin': 1,\n",
       " 'adscrev': 1,\n",
       " 'adst': 2,\n",
       " 'adstring': 1,\n",
       " 'adstrit': 95,\n",
       " 'aduan': 9,\n",
       " 'adult': 13,\n",
       " 'adulter': 7,\n",
       " 'adulterin': 2,\n",
       " 'adultéri': 5,\n",
       " 'aduz': 43,\n",
       " 'adv': 54,\n",
       " 'advei': 6,\n",
       " 'advenh': 18,\n",
       " 'adveni': 51,\n",
       " 'advent': 3,\n",
       " 'adventíci': 1,\n",
       " 'adverb': 1,\n",
       " 'advers': 17,\n",
       " 'adversar': 1,\n",
       " 'adversár': 1,\n",
       " 'advert': 36,\n",
       " 'advi': 23,\n",
       " 'advind': 14,\n",
       " 'advinh': 2,\n",
       " 'advir': 3,\n",
       " 'advirt': 1,\n",
       " 'advocac': 8,\n",
       " 'advocatíci': 2,\n",
       " 'advog': 319,\n",
       " 'advém': 24,\n",
       " 'advérbi': 4,\n",
       " 'advêm': 7,\n",
       " 'adäquanz': 1,\n",
       " 'aedificand': 9,\n",
       " 'aequ': 1,\n",
       " 'aequiparatur': 1,\n",
       " 'aequit': 1,\n",
       " 'aequum': 1,\n",
       " 'aerodinâm': 1,\n",
       " 'aeroger': 14,\n",
       " 'aerogin': 1,\n",
       " 'aeron': 3,\n",
       " 'aeronav': 11,\n",
       " 'aeroport': 2,\n",
       " 'aeroportod': 1,\n",
       " 'aeroportu': 1,\n",
       " 'aeroportuár': 1,\n",
       " 'af': 11,\n",
       " 'afas': 2,\n",
       " 'afast': 574,\n",
       " 'afe': 2,\n",
       " 'afec': 36,\n",
       " 'afect': 783,\n",
       " 'afer': 455,\n",
       " 'aferir': 1,\n",
       " 'afet': 100,\n",
       " 'afetiv': 2,\n",
       " 'afetu': 1,\n",
       " 'affecti': 4,\n",
       " 'affection': 1,\n",
       " 'afianç': 39,\n",
       " 'afig': 108,\n",
       " 'afigur': 31,\n",
       " 'afilh': 1,\n",
       " 'afim': 31,\n",
       " 'afin': 37,\n",
       " 'afinal': 85,\n",
       " 'afir': 2,\n",
       " 'afirm': 668,\n",
       " 'afirmativ': 4,\n",
       " 'afix': 9,\n",
       " 'afl': 5,\n",
       " 'aflit': 1,\n",
       " 'aflor': 29,\n",
       " 'aflu': 1,\n",
       " 'afm': 1,\n",
       " 'afog': 9,\n",
       " 'afons': 1,\n",
       " 'afor': 13,\n",
       " 'aforr': 21,\n",
       " 'afret': 7,\n",
       " 'afric': 1,\n",
       " 'afront': 42,\n",
       " 'afroux': 3,\n",
       " 'afugent': 1,\n",
       " 'afund': 8,\n",
       " 'afável': 1,\n",
       " 'ag': 12,\n",
       " 'agach': 1,\n",
       " 'agarr': 2,\n",
       " 'age': 105,\n",
       " 'agenc': 2,\n",
       " 'agenci': 4,\n",
       " 'agend': 10,\n",
       " 'agendum': 2,\n",
       " 'agent': 464,\n",
       " 'agenz': 1,\n",
       " 'agi': 3,\n",
       " 'agid': 83,\n",
       " 'agiliz': 7,\n",
       " 'agind': 53,\n",
       " 'agir': 200,\n",
       " 'agiss': 3,\n",
       " 'agit': 4,\n",
       " 'agiu': 101,\n",
       " 'aglom': 1,\n",
       " 'aglutin': 4,\n",
       " 'agnós': 1,\n",
       " 'agon': 2,\n",
       " 'agor': 236,\n",
       " 'agost': 157,\n",
       " 'agr': 14,\n",
       " 'agrac': 1,\n",
       " 'agraci': 2,\n",
       " 'agrad': 3,\n",
       " 'agradec': 1,\n",
       " 'agrav': 418,\n",
       " 'agred': 3,\n",
       " 'agreement': 3,\n",
       " 'agreg': 48,\n",
       " 'agrement': 1,\n",
       " 'agres': 6,\n",
       " 'agress': 34,\n",
       " 'agrest': 1,\n",
       " 'agricul': 6,\n",
       " 'agricult': 10,\n",
       " 'agrid': 1,\n",
       " 'agrup': 15,\n",
       " 'agrur': 1,\n",
       " 'agrár': 7,\n",
       " 'agrícol': 100,\n",
       " 'agu': 3,\n",
       " 'aguard': 41,\n",
       " 'agudiz': 3,\n",
       " 'agulh': 2,\n",
       " 'aguç': 2,\n",
       " 'agênc': 127,\n",
       " 'ai': 1,\n",
       " 'aim': 14,\n",
       " 'aind': 2404,\n",
       " 'aio': 1,\n",
       " 'aip': 1,\n",
       " 'air': 3,\n",
       " 'airway': 1,\n",
       " 'ait': 1,\n",
       " 'aja': 5,\n",
       " 'ajardin': 1,\n",
       " 'ajoelh': 1,\n",
       " 'ajud': 76,\n",
       " 'ajudic': 2,\n",
       " 'ajuiz': 122,\n",
       " 'ajust': 182,\n",
       " 'aktiengesetz': 1,\n",
       " 'al': 91,\n",
       " 'alag': 2,\n",
       " 'alamed': 1,\n",
       " 'alarg': 149,\n",
       " 'alarm': 18,\n",
       " 'albagest': 1,\n",
       " 'alberg': 3,\n",
       " 'albert': 12,\n",
       " 'albuf': 7,\n",
       " 'alcan': 2,\n",
       " 'alcanc': 180,\n",
       " 'alcandor': 1,\n",
       " 'alcantil': 1,\n",
       " 'alcanç': 248,\n",
       " 'alcool': 8,\n",
       " 'alcoolem': 59,\n",
       " 'alcooliz': 1,\n",
       " 'alcoolém': 17,\n",
       " 'alcoól': 9,\n",
       " 'ald': 36,\n",
       " 'alde': 5,\n",
       " 'ale': 3,\n",
       " 'aleatoriedad': 2,\n",
       " 'aleatór': 9,\n",
       " 'aleatóri': 30,\n",
       " 'aleg': 2786,\n",
       " 'alegad': 101,\n",
       " 'alegatór': 3,\n",
       " 'alegatóri': 15,\n",
       " 'alegr': 40,\n",
       " 'aleij': 5,\n",
       " 'alem': 41,\n",
       " 'alemanh': 8,\n",
       " 'alemã': 15,\n",
       " 'alert': 29,\n",
       " 'alexandr': 1,\n",
       " 'alf': 1,\n",
       " 'alfa': 1,\n",
       " 'alfandeg': 5,\n",
       " 'alfandegár': 1,\n",
       " 'alfândeg': 7,\n",
       " 'alg': 58,\n",
       " 'algali': 4,\n",
       " 'algar': 1,\n",
       " 'algeroz': 1,\n",
       " 'algum': 947,\n",
       " 'algur': 1,\n",
       " 'alguém': 205,\n",
       " 'alhe': 173,\n",
       " 'alhei': 248,\n",
       " 'ali': 295,\n",
       " 'alicerc': 6,\n",
       " 'alicerç': 43,\n",
       " 'alien': 515,\n",
       " 'alienatóri': 1,\n",
       " 'aligeir': 8,\n",
       " 'alij': 1,\n",
       " 'aliment': 502,\n",
       " 'alimentíc': 15,\n",
       " 'alimentíci': 2,\n",
       " 'aline': 2,\n",
       " 'alinh': 4,\n",
       " 'aliquot': 1,\n",
       " 'alit': 1,\n",
       " 'aliud': 6,\n",
       " 'alium': 5,\n",
       " 'aliund': 1,\n",
       " 'alivi': 4,\n",
       " 'aliás': 158,\n",
       " 'alm': 5,\n",
       " 'alme': 18,\n",
       " 'almedin': 17,\n",
       " 'almej': 26,\n",
       " 'almoç': 4,\n",
       " 'aloj': 26,\n",
       " 'along': 21,\n",
       " 'alopéc': 1,\n",
       " 'alpendr': 2,\n",
       " 'alquev': 1,\n",
       " 'alt': 186,\n",
       " 'alte': 1,\n",
       " 'alter': 1318,\n",
       " 'altern': 154,\n",
       " 'alternat': 3,\n",
       " 'alternativ': 1,\n",
       " 'alterum': 2,\n",
       " 'altruistic': 1,\n",
       " 'altruísm': 1,\n",
       " 'altruíst': 1,\n",
       " 'altur': 176,\n",
       " 'alu': 7,\n",
       " 'alud': 883,\n",
       " 'alug': 7,\n",
       " 'alugu': 94,\n",
       " 'alumíni': 2,\n",
       " 'alun': 26,\n",
       " 'alus': 35,\n",
       " 'alv': 23,\n",
       " 'alvar': 92,\n",
       " 'alvedri': 1,\n",
       " 'alven': 4,\n",
       " 'alvitr': 3,\n",
       " 'alª': 9,\n",
       " 'alç': 137,\n",
       " 'alçap': 2,\n",
       " 'alçaprem': 1,\n",
       " 'além': 915,\n",
       " 'alíne': 952,\n",
       " 'alíquot': 3,\n",
       " 'am': 11,\n",
       " 'amad': 1,\n",
       " 'amanh': 3,\n",
       " 'amanhã': 2,\n",
       " 'amar': 1,\n",
       " 'amarel': 4,\n",
       " 'amarg': 2,\n",
       " 'amargur': 1,\n",
       " 'amarr': 2,\n",
       " 'amb': 1,\n",
       " 'ambas': 300,\n",
       " 'ambi': 69,\n",
       " 'ambic': 1,\n",
       " 'ambient': 32,\n",
       " 'ambigu': 31,\n",
       " 'ambiguit': 2,\n",
       " 'ambos': 715,\n",
       " 'ambulatoriedad': 1,\n",
       " 'ambulatór': 6,\n",
       " 'ambulatóri': 5,\n",
       " 'ambulânc': 1,\n",
       " 'ambígu': 14,\n",
       " 'amealh': 1,\n",
       " 'ameaç': 69,\n",
       " 'ameixo': 1,\n",
       " 'americ': 5,\n",
       " 'amesquinh': 1,\n",
       " 'amiant': 1,\n",
       " 'amig': 35,\n",
       " 'amiotrof': 1,\n",
       " 'amizad': 10,\n",
       " 'amiúd': 2,\n",
       " 'amnist': 3,\n",
       " 'amnisti': 2,\n",
       " 'amnés': 4,\n",
       " 'amo': 2,\n",
       " 'amolec': 1,\n",
       " 'amolg': 2,\n",
       " 'amonitór': 1,\n",
       " 'amor': 10,\n",
       " 'amorim': 1,\n",
       " 'amort': 51,\n",
       " 'amortiz': 2,\n",
       " 'amostr': 14,\n",
       " 'amov': 4,\n",
       " 'ampar': 9,\n",
       " 'ampl': 155,\n",
       " 'amplex': 2,\n",
       " 'ampli': 346,\n",
       " 'ampliand': 1,\n",
       " 'amplific': 1,\n",
       " 'amplitud': 62,\n",
       " 'amput': 23,\n",
       " 'amur': 2,\n",
       " 'amálgam': 1,\n",
       " 'amânci': 5,\n",
       " 'anal': 2,\n",
       " 'analfabet': 4,\n",
       " 'analgés': 3,\n",
       " 'analis': 141,\n",
       " 'analog': 91,\n",
       " 'analogic': 24,\n",
       " 'analí': 3,\n",
       " 'analóg': 66,\n",
       " 'anatoc': 4,\n",
       " 'anatom': 2,\n",
       " 'anatomopatolog': 1,\n",
       " 'anc': 17,\n",
       " 'ancestr': 1,\n",
       " 'ancil': 1,\n",
       " 'ancor': 19,\n",
       " 'and': 163,\n",
       " 'andaim': 1,\n",
       " 'andorr': 1,\n",
       " 'andrad': 5,\n",
       " 'andré': 3,\n",
       " 'anedon': 1,\n",
       " 'anestes': 11,\n",
       " 'aneurism': 5,\n",
       " 'anex': 82,\n",
       " 'anfordern': 1,\n",
       " 'ang': 2,\n",
       " 'angar': 1,\n",
       " 'angari': 61,\n",
       " 'angl': 5,\n",
       " 'angol': 7,\n",
       " 'angul': 2,\n",
       " 'angust': 2,\n",
       " 'angusti': 8,\n",
       " 'angúst': 62,\n",
       " 'anim': 7,\n",
       " 'animal': 83,\n",
       " 'animos': 1,\n",
       " 'animu': 145,\n",
       " 'animusd': 1,\n",
       " 'aniquil': 4,\n",
       " 'aniversári': 3,\n",
       " 'annahmewillensbetätigung': 1,\n",
       " 'ano': 1708,\n",
       " 'anoitec': 1,\n",
       " 'anomal': 64,\n",
       " 'anonimat': 1,\n",
       " 'anorm': 91,\n",
       " 'anormal': 7,\n",
       " 'anot': 27,\n",
       " 'anquilos': 4,\n",
       " 'anselm': 1,\n",
       " 'ansi': 7,\n",
       " 'ansiedad': 25,\n",
       " 'ant': 1800,\n",
       " 'antagon': 5,\n",
       " 'antagón': 7,\n",
       " 'antavamédil': 1,\n",
       " 'antebraç': 10,\n",
       " 'anteced': 184,\n",
       " 'anteces': 45,\n",
       " 'antecip': 169,\n",
       " 'antecipad': 35,\n",
       " 'antecipatory': 2,\n",
       " 'antecipatór': 5,\n",
       " 'antecipatóri': 2,\n",
       " 'antedit': 1,\n",
       " 'anten': 2,\n",
       " 'antenupc': 3,\n",
       " 'antepass': 1,\n",
       " 'antepossu': 9,\n",
       " 'anter': 1,\n",
       " 'anteri': 1261,\n",
       " 'anterior': 44,\n",
       " 'antev': 15,\n",
       " 'antevis': 1,\n",
       " 'antevésp': 1,\n",
       " 'antibió': 1,\n",
       " 'anticatól': 1,\n",
       " 'anticipatory': 2,\n",
       " 'anticleric': 1,\n",
       " 'antiform': 1,\n",
       " 'antig': 99,\n",
       " 'antigu': 15,\n",
       " 'antigéni': 1,\n",
       " 'antijuric': 2,\n",
       " 'antijuridic': 3,\n",
       " 'antijuríd': 7,\n",
       " 'antinom': 6,\n",
       " 'antinóm': 6,\n",
       " 'antipat': 1,\n",
       " 'antité': 1,\n",
       " 'antié': 1,\n",
       " 'antolh': 3,\n",
       " 'antonomás': 1,\n",
       " 'antropológ': 1,\n",
       " 'antróg': 1,\n",
       " 'antun': 31,\n",
       " 'antípod': 2,\n",
       " 'anu': 32,\n",
       " 'anual': 90,\n",
       " 'anul': 744,\n",
       " 'anulabil': 253,\n",
       " 'anulabl': 1,\n",
       " 'anuland': 4,\n",
       " 'anulatór': 22,\n",
       " 'anulatóri': 8,\n",
       " 'anunc': 3,\n",
       " 'anunci': 30,\n",
       " 'anuír': 1,\n",
       " 'anuíss': 1,\n",
       " 'anvers': 1,\n",
       " 'anzol': 3,\n",
       " 'anális': 208,\n",
       " 'análog': 83,\n",
       " 'anát': 7,\n",
       " 'aním': 7,\n",
       " 'anódin': 2,\n",
       " 'anóm': 1,\n",
       " 'anómal': 37,\n",
       " 'anón': 53,\n",
       " 'anúnci': 29,\n",
       " 'aobrig': 1,\n",
       " 'aond': 1,\n",
       " 'ap': 5,\n",
       " 'apadrinh': 2,\n",
       " 'apag': 20,\n",
       " 'apanh': 4,\n",
       " 'apanági': 10,\n",
       " 'apar': 89,\n",
       " 'aparc': 20,\n",
       " 'aparec': 48,\n",
       " 'aparelh': 26,\n",
       " 'aparent': 129,\n",
       " 'apareç': 2,\n",
       " 'apart': 49,\n",
       " 'apascent': 5,\n",
       " 'apat': 2,\n",
       " 'apb': 160,\n",
       " 'ape': 4,\n",
       " 'apeg': 5,\n",
       " 'apel': 760,\n",
       " 'apelid': 11,\n",
       " 'apen': 3370,\n",
       " 'apens': 86,\n",
       " 'aperceb': 53,\n",
       " 'aperfeiço': 135,\n",
       " 'apert': 25,\n",
       " 'apertu': 1,\n",
       " 'apes': 565,\n",
       " 'apet': 3,\n",
       " 'apetec': 1,\n",
       " 'apetrech': 2,\n",
       " 'apilic': 1,\n",
       " 'apl': 3,\n",
       " 'aplan': 1,\n",
       " 'aplaud': 1,\n",
       " 'aplaus': 3,\n",
       " 'aplic': 3585,\n",
       " 'aplicac': 1,\n",
       " 'aplicand': 1,\n",
       " 'apliqu': 17,\n",
       " 'apne': 2,\n",
       " 'apo': 17,\n",
       " 'apod': 9,\n",
       " 'apoder': 2,\n",
       " 'apoditic': 1,\n",
       " 'apodrec': 4,\n",
       " 'apodíc': 6,\n",
       " 'apoi': 137,\n",
       " 'apond': 4,\n",
       " 'aponh': 1,\n",
       " 'apont': 219,\n",
       " 'aport': 5,\n",
       " 'apos': 35,\n",
       " 'aposent': 14,\n",
       " 'aposs': 12,\n",
       " 'apost': 103,\n",
       " 'appel': 1,\n",
       " 'apport': 1,\n",
       " 'apprehensi': 1,\n",
       " 'apr': 2,\n",
       " 'apraz': 7,\n",
       " 'aprec': 2,\n",
       " 'apreci': 2089,\n",
       " 'apreeend': 1,\n",
       " 'apreend': 66,\n",
       " 'apreens': 90,\n",
       " 'aprego': 3,\n",
       " 'aprendiz': 8,\n",
       " 'apres': 50,\n",
       " 'apresent': 1259,\n",
       " 'apress': 1,\n",
       " 'aprest': 9,\n",
       " 'apreç': 162,\n",
       " 'aprioristic': 5,\n",
       " 'apriorís': 4,\n",
       " 'aprofund': 8,\n",
       " 'apront': 2,\n",
       " 'apropri': 90,\n",
       " 'aprouv': 8,\n",
       " 'aprov': 521,\n",
       " 'aprove': 49,\n",
       " 'aproveit': 239,\n",
       " 'aprovision': 2,\n",
       " 'aprox': 11,\n",
       " 'aproxim': 111,\n",
       " 'aproximad': 6,\n",
       " 'aps': 2,\n",
       " 'apt': 120,\n",
       " 'aptidã': 88,\n",
       " 'apur': 836,\n",
       " 'apus': 3,\n",
       " 'apá': 1,\n",
       " 'apícol': 2,\n",
       " 'apófis': 1,\n",
       " 'apól': 165,\n",
       " 'após': 726,\n",
       " 'apóstrof': 1,\n",
       " 'apô': 4,\n",
       " 'apõ': 1,\n",
       " 'aqs': 2,\n",
       " 'aqu': 657,\n",
       " 'aquedut': 17,\n",
       " 'aquelasquest': 1,\n",
       " 'aqueloutr': 17,\n",
       " 'aqueç': 1,\n",
       " 'aquiesc': 6,\n",
       " 'aquil': 2,\n",
       " 'aquilat': 36,\n",
       " 'aquili': 40,\n",
       " 'aquir': 1,\n",
       " 'aquis': 936,\n",
       " 'aquisi': 45,\n",
       " 'aquá': 8,\n",
       " 'aquém': 11,\n",
       " 'aquífer': 1,\n",
       " 'ar': 2,\n",
       " 'ara': 3,\n",
       " 'arag': 1,\n",
       " 'aram': 1,\n",
       " 'arbitr': 657,\n",
       " 'arbitrariedad': 6,\n",
       " 'arbitration': 1,\n",
       " 'arbitrár': 40,\n",
       " 'arbus': 1,\n",
       " 'arbust': 1,\n",
       " 'arbítri': 29,\n",
       " 'arbóre': 2,\n",
       " 'arc': 18,\n",
       " 'ard': 4,\n",
       " 'ardil': 2,\n",
       " 'are': 12,\n",
       " 'areal': 1,\n",
       " 'areiaç': 1,\n",
       " 'arej': 3,\n",
       " 'aren': 1,\n",
       " 'arest': 88,\n",
       " 'argamass': 1,\n",
       " 'argil': 1,\n",
       " 'argu': 520,\n",
       " 'argument': 295,\n",
       " 'arguí': 1,\n",
       " 'argú': 1,\n",
       " 'aritmetic': 1,\n",
       " 'aritmé': 24,\n",
       " 'arm': 26,\n",
       " 'armad': 1,\n",
       " 'armadilh': 1,\n",
       " 'armazen': 21,\n",
       " 'armazém': 29,\n",
       " 'armári': 3,\n",
       " 'armén': 1,\n",
       " 'arn': 1,\n",
       " 'aro': 1,\n",
       " 'aromá': 1,\n",
       " 'arouc': 1,\n",
       " 'arqbuilding': 1,\n",
       " 'arqu': 7,\n",
       " 'arqueológ': 6,\n",
       " 'arquitect': 36,\n",
       " 'arquitectón': 17,\n",
       " 'arquitet': 1,\n",
       " 'arquitetón': 1,\n",
       " 'arquiv': 30,\n",
       " 'arquétip': 3,\n",
       " 'arr': 10,\n",
       " 'arranc': 9,\n",
       " 'arranj': 20,\n",
       " 'arranqu': 7,\n",
       " 'arraso': 1,\n",
       " 'arrast': 31,\n",
       " 'arrazo': 2,\n",
       " 'arread': 1,\n",
       " 'arrecad': 17,\n",
       " 'arred': 52,\n",
       " 'arredi': 1,\n",
       " 'arredond': 8,\n",
       " 'arrefec': 1,\n",
       " 'arregiment': 1,\n",
       " 'arreig': 3,\n",
       " 'arrel': 2,\n",
       " 'arrem': 1,\n",
       " 'arremat': 20,\n",
       " 'arremess': 7,\n",
       " 'arren': 1,\n",
       " 'arrend': 1090,\n",
       " 'arrendat': 450,\n",
       " 'arrendatár': 96,\n",
       " 'arrendatíci': 3,\n",
       " 'arrepend': 11,\n",
       " 'arrepi': 28,\n",
       " 'arrest': 110,\n",
       " 'arrib': 2,\n",
       " 'arrim': 8,\n",
       " 'arrisc': 4,\n",
       " 'arrog': 111,\n",
       " 'arrol': 23,\n",
       " 'arromb': 3,\n",
       " 'arroz': 1,\n",
       " 'arru': 3,\n",
       " 'arruin': 1,\n",
       " 'arrum': 14,\n",
       " 'arrêt': 1,\n",
       " 'arsen': 1,\n",
       " 'art': 14024,\n",
       " 'artefact': 1,\n",
       " 'arter': 5,\n",
       " 'arterioscleros': 1,\n",
       " 'artesan': 5,\n",
       " 'artesi': 1,\n",
       " 'articul': 375,\n",
       " 'articulad': 1,\n",
       " 'artific': 10,\n",
       " 'artifici': 4,\n",
       " 'artifíci': 17,\n",
       " 'artig': 5284,\n",
       " 'artil': 40,\n",
       " 'artist': 11,\n",
       " 'artroplast': 1,\n",
       " 'artros': 2,\n",
       " 'artsº': 1,\n",
       " 'artª': 3,\n",
       " 'artº': 1238,\n",
       " 'artér': 5,\n",
       " 'artíst': 24,\n",
       " 'arv': 1,\n",
       " 'arvens': 8,\n",
       " 'arvor': 5,\n",
       " 'arvored': 3,\n",
       " 'arº': 1,\n",
       " 'ascen': 8,\n",
       " 'ascend': 68,\n",
       " 'ascens': 2,\n",
       " 'asfalt': 9,\n",
       " 'asfix': 3,\n",
       " 'asi': 1,\n",
       " 'aso': 2,\n",
       " 'asp': 3,\n",
       " 'aspect': 166,\n",
       " 'aspet': 13,\n",
       " 'aspir': 8,\n",
       " 'ass': 2,\n",
       " 'assac': 36,\n",
       " 'assad': 1,\n",
       " 'assalari': 3,\n",
       " 'assalt': 3,\n",
       " 'assaz': 7,\n",
       " 'asseg': 39,\n",
       " 'assegur': 397,\n",
       " 'assemble': 337,\n",
       " 'assemelh': 3,\n",
       " 'assent': 826,\n",
       " 'asserç': 19,\n",
       " 'assess': 6,\n",
       " 'assessor': 2,\n",
       " 'assev': 1,\n",
       " 'assever': 2,\n",
       " 'assidu': 1,\n",
       " 'assim': 2273,\n",
       " 'assimetr': 3,\n",
       " 'assimil': 20,\n",
       " 'assin': 234,\n",
       " 'assinal': 78,\n",
       " 'assinat': 290,\n",
       " 'assinton': 2,\n",
       " 'assist': 376,\n",
       " 'assistanc': 2,\n",
       " 'assistir': 8,\n",
       " 'assoalh': 1,\n",
       " 'assoc': 13,\n",
       " 'associ': 415,\n",
       " 'association': 1,\n",
       " 'assol': 1,\n",
       " 'asssim': 1,\n",
       " 'assum': 978,\n",
       " 'assumid': 2,\n",
       " 'assumir': 4,\n",
       " 'assump': 1,\n",
       " 'assumpç': 16,\n",
       " 'assun': 17,\n",
       " 'assunt': 49,\n",
       " 'assunç': 125,\n",
       " 'assust': 1,\n",
       " 'assídu': 2,\n",
       " 'astorg': 1,\n",
       " 'astucios': 1,\n",
       " 'at': 9,\n",
       " 'ata': 8,\n",
       " 'atabalho': 1,\n",
       " 'atac': 36,\n",
       " 'atalh': 4,\n",
       " 'ataqu': 8,\n",
       " 'atavi': 1,\n",
       " 'ate': 3,\n",
       " 'ateli': 2,\n",
       " 'atemp': 35,\n",
       " 'atempad': 36,\n",
       " 'aten': 1,\n",
       " 'atend': 556,\n",
       " 'atendibil': 10,\n",
       " 'atent': 416,\n",
       " 'atentamemt': 1,\n",
       " 'atentatór': 7,\n",
       " 'atentatóri': 9,\n",
       " 'atentór': 1,\n",
       " 'atentóri': 1,\n",
       " 'atenu': 65,\n",
       " 'atenç': 167,\n",
       " 'aterr': 15,\n",
       " 'atest': 65,\n",
       " 'atev': 1,\n",
       " 'atid': 2,\n",
       " 'atig': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = cv.get_feature_names()\n",
    "count_list = X.toarray().sum(axis=0)   \n",
    "bow_dic = dict(zip(word_list,count_list))\n",
    "bow_dic\n",
    "\n",
    "remove_words = []\n",
    "\n",
    "for docs in features['words'].to_list():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-8fd4dc5693df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbow_dic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyLDAvis\\gensim.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyLDAvis\\gensim.py\u001b[0m in \u001b[0;36m_extract_data\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m       \u001b[0mcorpus_csc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus2csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_terms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m       \u001b[0mcorpus_csc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py\u001b[0m in \u001b[0;36mcorpus2csc\u001b[1;34m(corpus, num_terms, dtype, num_docs, num_nnz, printprogress)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;31m# zip(*doc) transforms doc to (token_indices, token_counts]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mdoc_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, features['words'].apply(' '.join), bow_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'show_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-543b07a062bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'show_topics'"
     ]
    }
   ],
   "source": [
    "lda.show_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-b2f4fd7add11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaMulticore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         )\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no word id mapping provided; initializing from corpus, assuming identity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdict_from_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mdict_from_corpus\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m     \"\"\"\n\u001b[1;32m--> 826\u001b[1;33m     \u001b[0mnum_terms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_max_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m     \u001b[0mid2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFakeDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mget_max_id\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m    733\u001b[0m     \u001b[0mmaxid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m             \u001b[0mmaxid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfieldid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfieldid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaxid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__bool__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             raise ValueError(\"The truth value of an array with more than one \"\n\u001b[0m\u001b[0;32m    288\u001b[0m                              \"element is ambiguous. Use a.any() or a.all().\")\n\u001b[0;32m    289\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "lda_model = LdaMulticore(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
